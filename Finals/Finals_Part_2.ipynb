{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hatim/anaconda/lib/python3.6/site-packages/numpy/linalg/linalg.py:1546: RuntimeWarning: invalid value encountered in greater\n",
      "  return sum(S > tol)\n",
      "/Users/Hatim/anaconda/lib/python3.6/site-packages/statsmodels/base/data.py:503: FutureWarning: TimeSeries is deprecated. Please use Series\n",
      "  return TimeSeries(result, index=self.predict_dates)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'References:\\n        Machine Learning: An algorithmic perspective'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "\n",
    "\n",
    "H=5 #trading horizon\n",
    "file1 = 'Constant_Maturity_EDs.csv'\n",
    "ed_data_constant_maturity = pd.read_csv(file1, index_col= 0)\n",
    "ed_data_constant_maturity.index = pd.to_datetime(ed_data_constant_maturity.index)\n",
    "\n",
    "\n",
    "sample_A = ed_data_constant_maturity.ix['2011-06-01':'2014-01-31',:]\n",
    "sample_B = ed_data_constant_maturity.ix['2014-06-15':'2015-06-15',:]\n",
    "sample_C = ed_data_constant_maturity.ix['2015-06-15':'2016-06-14',:]\n",
    " \n",
    "def halflife(z):\n",
    "    z_lag = z.shift(1)\n",
    "    z_lag.ix[0] = z_lag.ix[1]\n",
    "    z_ret = z - z_lag\n",
    "    z_ret.ix[0] = z_ret.ix[1]\n",
    "    z_lag2 = sm.add_constant(z_lag)\n",
    "    model = sm.OLS(z_ret,z_lag2)\n",
    "    res = model.fit()\n",
    "    halflife = round(-np.log(2) / res.params[1],0)\n",
    "    return halflife\n",
    "\n",
    "def Cointegration(a1,a2):\n",
    "    coint_= sm.OLS(a1,a2).fit()\n",
    "    coint=pd.Series(a1) - pd.Series(coint_.params.ix[0]*a2)\n",
    "    return coint,coint_\n",
    "\n",
    "def Signal1(a):\n",
    "    m = AR(a).fit(1)\n",
    "    predict=m.predict()\n",
    "    return predict,m\n",
    "    \n",
    "def Signal2(a,alpha):\n",
    "    signal2=a-pd.Series(a).ewm(alpha=alpha).mean()\n",
    "    predict1,error1=Signal1(signal2)\n",
    "    return predict1\n",
    "                \n",
    "\n",
    "\n",
    "cointA23, paramA23 = Cointegration(sample_A.ix[:,'2.0Y'],sample_A.ix[:,'3.0Y'])\n",
    "cointA34,paramA34 = Cointegration(sample_A.ix[:,'3.0Y'],sample_A.ix[:,'4.0Y'])\n",
    "cointA45,paramA45 = Cointegration(sample_A.ix[:,'4.0Y'],sample_A.ix[:,'4.75Y'])\n",
    "\n",
    "signal1A23,a23 =  Signal1(cointA23)\n",
    "signal1A34,a34 =  Signal1(cointA23)\n",
    "signal1A45,a45 =  Signal1(cointA23)\n",
    "\n",
    "HLA_23=halflife(signal1A23)\n",
    "HLA_34=halflife(signal1A34)\n",
    "HLA_45=halflife(signal1A45)\n",
    "\n",
    "\n",
    "alpha= 1- np.exp(np.log(0.5)/10)\n",
    "signal2A23=Signal2(cointA23,alpha)\n",
    "signal2A34=Signal2(cointA34,alpha)\n",
    "signal2A45=Signal2(cointA45,alpha)\n",
    "\n",
    " \n",
    "coint23B,mod23B=Cointegration(sample_B.ix[:,'2.0Y'],sample_B.ix[:,'3.0Y'])\n",
    "coint34B,mod34B=Cointegration(sample_B.ix[:,'3.0Y'],sample_B.ix[:,'4.0Y'])\n",
    "coint45B,mod45B=Cointegration(sample_B.ix[:,'4.0Y'],sample_B.ix[:,'4.75Y'])\n",
    "\n",
    "def forecast(t,param):\n",
    "    beta=param.params[1]\n",
    "    c=param.params[0]\n",
    "    t_for=(beta**H)*t+ c*((1-beta**H)/(1-beta))\n",
    "    return t_for\n",
    "    \n",
    "\n",
    "\"\"\"Algorithm:\n",
    "    \n",
    "    By using the Gaussian Mixture function from the sklearn module, and varying the\n",
    "    values of different weights parameter, we can find the optimal thetas.\n",
    "    \n",
    "    pseudo code for GMM:\n",
    "        we select random thetas, find the variance of the dataset. Then we use the \n",
    "        expectation maximisation algorithm.\n",
    "        guess parameters,repeat the following until convergence:\n",
    "            compute the expectation \n",
    "            Estimate the new parameters\"\"\"\n",
    "            \n",
    "\"\"\"References:\n",
    "        Machine Learning: An algorithmic perspective\"\"\"\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
